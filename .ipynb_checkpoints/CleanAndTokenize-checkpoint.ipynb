{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:38:51.511619Z",
     "start_time": "2021-02-18T23:38:51.385623Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyopencl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a1e3fe8d0749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyopencl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcl\u001b[0m \u001b[0;31m#ONLY RUN THIS IF YOU'RE USING GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyopencl'"
     ]
    }
   ],
   "source": [
    "import pyopencl as cl #ONLY RUN THIS IF YOU'RE USING GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:38:53.011623Z",
     "start_time": "2021-02-18T23:38:51.512621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1076)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1076)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1076)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:38:53.307622Z",
     "start_time": "2021-02-18T23:38:53.013624Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:38:56.470621Z",
     "start_time": "2021-02-18T23:38:53.309624Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_df = pd.read_csv('./data/pre_soccer_replaced.csv')\n",
    "post_df = pd.read_csv('./data/post_soccer_replaced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pre_df=pre_df[pre_df['ptitle'].isna()==False]\n",
    "post_df=post_df[pre_df['ptitle'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:38:56.548621Z",
     "start_time": "2021-02-18T23:38:56.536625Z"
    }
   },
   "outputs": [],
   "source": [
    "def TokenizeProcess(df):\n",
    "    word_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    df_tk = pd.DataFrame(columns=['ptitle', 'pscore', 'pid', 'pbody', 'pcreated', 'comment', 'cauthor', 'ccreated'])\n",
    "\n",
    "    for (ptitle, pscore, pid, pbody, pcreated, comment, cauthor, ccreated) in df.values.tolist():\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(str(comment).lower())\n",
    "\n",
    "        # Strip punctuation\n",
    "        punctuation_list = str.maketrans('', '', string.punctuation)\n",
    "        tokens_strp = [w.translate(punctuation_list) for w in tokens]\n",
    "\n",
    "        # Remove other non-alphabetic tokens\n",
    "        words = [word for word in tokens_strp if word.isalpha()]\n",
    "\n",
    "        # Stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "        # Lemmatize\n",
    "        # Note: We might need to do this for the brands we want to detect as well\n",
    "        words_lm = [word_lemmatizer.lemmatize(w) for w in words]\n",
    "        df_tk = df_tk.append({\"ptitle\": ptitle, 'pscore':pscore, 'pid':pid, 'pbody':pbody, 'pcreated': pcreated, 'comment': words_lm, 'cauthor': cauthor, 'ccreated': ccreated} ,ignore_index=True) \n",
    "    return df_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:41:01.732651Z",
     "start_time": "2021-02-18T23:38:56.550622Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_df_tk = TokenizeProcess(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#pre_df=pre_df_tk\n",
    "pre_df['pcreated_date']=[datetime.fromtimestamp(x) for x in pre_df['pcreated']]\n",
    "post_df['pcreated_date']=[datetime.fromtimestamp(x) for x in post_df['pcreated']]\n",
    "pre_df['ccreated_date']=[datetime.fromtimestamp(x) for x in pre_df['ccreated']]\n",
    "#post_df['ccreated']=[datetime.fromtimestamp(x) for x in post_df['ccreated']]\n",
    "\n",
    "# 1. I have fix dates \n",
    "# 2. Seperate the teams out from title, pickle the files\n",
    "# 3. Anu -> sentiment analysis\n",
    "# 4. Sid -> Report starting\n",
    "# 5. Bog -> front-end, matching\n",
    "\n",
    "\n",
    "teams = pd.read_csv('./data/teams.csv')\n",
    "def getinvolved(df,column):\n",
    "    allteams=[]\n",
    "    missed=[]\n",
    "    for title in df[column]:\n",
    "        involvedteams=[]\n",
    "        for teamname,teamfull in teams.values:\n",
    "            if(teamname in title or teamfull in title):\n",
    "                involvedteams.append(teamname)\n",
    "        involvedteams=list(set(involvedteams))\n",
    "        involvedteams.sort()\n",
    "        if(len(involvedteams)!=2):\n",
    "            print(title,involvedteams)\n",
    "            missed.append(title)\n",
    "            allteams.append(\"None\")\n",
    "        else:\n",
    "            allteams.append(\" vs \".join(involvedteams))\n",
    "    df['involved_teams'] = allteams\n",
    "    df=df[df['involved_teams']!=\"None\"].reset_index(drop=True)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "pre_df=getinvolved(pre_df,'ptitle')\n",
    "post_df=getinvolved(post_df,'ptitle')\n",
    "pre_post=pd.merge(pre_df,post_df[['ptitle','pcreated','pcreated_date','involved_teams']],left_on=\"involved_teams\",right_on=\"involved_teams\",how='left')\n",
    "pre_post['diff'] = pre_post['pcreated_date_y']-pre_post['pcreated_date_x']\n",
    "\n",
    "pre_post['diff'] = [x.days for x in pre_post['diff']]\n",
    "pre_post=pre_post[(pre_post['diff'].isna()==False) & (pre_post['diff']<=20)]\n",
    "pre_df.drop_duplicates(\"pid\").to_csv(\"./data/unique_pre.csv\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptitle</th>\n",
       "      <th>pscore</th>\n",
       "      <th>pid</th>\n",
       "      <th>pbody</th>\n",
       "      <th>pcreated</th>\n",
       "      <th>comment</th>\n",
       "      <th>cauthor</th>\n",
       "      <th>ccreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pre-match thread] porto vs Juventusntus (cham...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>lls3ua</td>\n",
       "      <td>**Porto vs Juventus**\\n\\nCompetition: UEFA Cha...</td>\n",
       "      <td>1.613589e+09</td>\n",
       "      <td>[stop, sporting, winning, league, least, make,...</td>\n",
       "      <td>idek0k</td>\n",
       "      <td>1.613592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pre-match thread] porto vs Juventusntus (cham...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>lls3ua</td>\n",
       "      <td>**Porto vs Juventus**\\n\\nCompetition: UEFA Cha...</td>\n",
       "      <td>1.613589e+09</td>\n",
       "      <td>[nt, fLyonlow, liga, no, closely, portuguese, ...</td>\n",
       "      <td>kuzjaruge</td>\n",
       "      <td>1.613590e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pre-match thread] porto vs Juventusntus (cham...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>lls3ua</td>\n",
       "      <td>**Porto vs Juventus**\\n\\nCompetition: UEFA Cha...</td>\n",
       "      <td>1.613589e+09</td>\n",
       "      <td>[go, porto, get, win, look, match, thread, pop...</td>\n",
       "      <td>TweakyWatson</td>\n",
       "      <td>1.613591e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[pre-match thread] porto vs Juventusntus (cham...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>lls3ua</td>\n",
       "      <td>**Porto vs Juventus**\\n\\nCompetition: UEFA Cha...</td>\n",
       "      <td>1.613589e+09</td>\n",
       "      <td>[shame, fan, allowed, stadium, think, would, l...</td>\n",
       "      <td>rabbitvinyl</td>\n",
       "      <td>1.613596e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[pre-match thread] porto vs Juventusntus (cham...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>lls3ua</td>\n",
       "      <td>**Porto vs Juventus**\\n\\nCompetition: UEFA Cha...</td>\n",
       "      <td>1.613589e+09</td>\n",
       "      <td>[Juventusntus, take, easily, porto, fairly, de...</td>\n",
       "      <td>NunoxGames</td>\n",
       "      <td>1.613591e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20038</th>\n",
       "      <td>[pre match thread] liverpoLyon vs manchester M...</td>\n",
       "      <td>733.0</td>\n",
       "      <td>89o822</td>\n",
       "      <td>[](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...</td>\n",
       "      <td>1.522866e+09</td>\n",
       "      <td>[klopperinho, v, fraudiLyona, goal, minimum, p...</td>\n",
       "      <td>Tanners</td>\n",
       "      <td>1.522866e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20039</th>\n",
       "      <td>[pre match thread] liverpoLyon vs manchester M...</td>\n",
       "      <td>733.0</td>\n",
       "      <td>89o822</td>\n",
       "      <td>[](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...</td>\n",
       "      <td>1.522866e+09</td>\n",
       "      <td>[stalemate]</td>\n",
       "      <td>DMmi</td>\n",
       "      <td>1.522871e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20040</th>\n",
       "      <td>[pre match thread] liverpoLyon vs manchester M...</td>\n",
       "      <td>733.0</td>\n",
       "      <td>89o822</td>\n",
       "      <td>[](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...</td>\n",
       "      <td>1.522866e+09</td>\n",
       "      <td>[need, want, something, even, last, match]</td>\n",
       "      <td>_cumblast_</td>\n",
       "      <td>1.522867e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20041</th>\n",
       "      <td>[pre match thread] liverpoLyon vs manchester M...</td>\n",
       "      <td>733.0</td>\n",
       "      <td>89o822</td>\n",
       "      <td>[](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...</td>\n",
       "      <td>1.522866e+09</td>\n",
       "      <td>[absLyonutely, fascinating, match, due, many, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.522877e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>[pre match thread] liverpoLyon vs manchester M...</td>\n",
       "      <td>733.0</td>\n",
       "      <td>89o822</td>\n",
       "      <td>[](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...</td>\n",
       "      <td>1.522866e+09</td>\n",
       "      <td>[arse, completely, gone, much, happier, first,...</td>\n",
       "      <td>Thesolly180</td>\n",
       "      <td>1.522866e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20043 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ptitle  pscore     pid  \\\n",
       "0      [pre-match thread] porto vs Juventusntus (cham...    64.0  lls3ua   \n",
       "1      [pre-match thread] porto vs Juventusntus (cham...    64.0  lls3ua   \n",
       "2      [pre-match thread] porto vs Juventusntus (cham...    64.0  lls3ua   \n",
       "3      [pre-match thread] porto vs Juventusntus (cham...    64.0  lls3ua   \n",
       "4      [pre-match thread] porto vs Juventusntus (cham...    64.0  lls3ua   \n",
       "...                                                  ...     ...     ...   \n",
       "20038  [pre match thread] liverpoLyon vs manchester M...   733.0  89o822   \n",
       "20039  [pre match thread] liverpoLyon vs manchester M...   733.0  89o822   \n",
       "20040  [pre match thread] liverpoLyon vs manchester M...   733.0  89o822   \n",
       "20041  [pre match thread] liverpoLyon vs manchester M...   733.0  89o822   \n",
       "20042  [pre match thread] liverpoLyon vs manchester M...   733.0  89o822   \n",
       "\n",
       "                                                   pbody      pcreated  \\\n",
       "0      **Porto vs Juventus**\\n\\nCompetition: UEFA Cha...  1.613589e+09   \n",
       "1      **Porto vs Juventus**\\n\\nCompetition: UEFA Cha...  1.613589e+09   \n",
       "2      **Porto vs Juventus**\\n\\nCompetition: UEFA Cha...  1.613589e+09   \n",
       "3      **Porto vs Juventus**\\n\\nCompetition: UEFA Cha...  1.613589e+09   \n",
       "4      **Porto vs Juventus**\\n\\nCompetition: UEFA Cha...  1.613589e+09   \n",
       "...                                                  ...           ...   \n",
       "20038  [](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...  1.522866e+09   \n",
       "20039  [](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...  1.522866e+09   \n",
       "20040  [](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...  1.522866e+09   \n",
       "20041  [](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...  1.522866e+09   \n",
       "20042  [](#sprite1-p3) [](#bar-1-gold)[](#bar-1-white...  1.522866e+09   \n",
       "\n",
       "                                                 comment       cauthor  \\\n",
       "0      [stop, sporting, winning, league, least, make,...        idek0k   \n",
       "1      [nt, fLyonlow, liga, no, closely, portuguese, ...     kuzjaruge   \n",
       "2      [go, porto, get, win, look, match, thread, pop...  TweakyWatson   \n",
       "3      [shame, fan, allowed, stadium, think, would, l...   rabbitvinyl   \n",
       "4      [Juventusntus, take, easily, porto, fairly, de...    NunoxGames   \n",
       "...                                                  ...           ...   \n",
       "20038  [klopperinho, v, fraudiLyona, goal, minimum, p...       Tanners   \n",
       "20039                                        [stalemate]          DMmi   \n",
       "20040         [need, want, something, even, last, match]    _cumblast_   \n",
       "20041  [absLyonutely, fascinating, match, due, many, ...           NaN   \n",
       "20042  [arse, completely, gone, much, happier, first,...   Thesolly180   \n",
       "\n",
       "           ccreated  \n",
       "0      1.613592e+09  \n",
       "1      1.613590e+09  \n",
       "2      1.613591e+09  \n",
       "3      1.613596e+09  \n",
       "4      1.613591e+09  \n",
       "...             ...  \n",
       "20038  1.522866e+09  \n",
       "20039  1.522871e+09  \n",
       "20040  1.522867e+09  \n",
       "20041  1.522877e+09  \n",
       "20042  1.522866e+09  \n",
       "\n",
       "[20043 rows x 8 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.drop_duplicates(\"ptitle\").to_csv(\"unique_pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:46:33.119685Z",
     "start_time": "2021-02-18T23:41:01.733621Z"
    }
   },
   "outputs": [],
   "source": [
    "#post_df_tk = TokenizeProcess(post_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:48:08.574599Z",
     "start_time": "2021-02-18T23:48:02.664885Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_df_tk.to_csv(\"./data/pre_soccer_tokenized.csv\",index=False)\n",
    "#post_df_tk.to_csv(\"./data/post_soccer_tokenized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( pre_df_tk, open( \"./data/pre_df_tk.p\", \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit4ada4739344a444e86dc35e0d095141c"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
